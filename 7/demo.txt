Improper Content Detection on the Social Media using AI
Social media such as Meta, X, Instagram, WhatsApp and other social network platforms can have people freely speak what they want to say on the Internet. That’s the freedom of speech. However, there are some comments related to detrimental information including fake news, hate speech and aggressive words which may raise up a major concern in the society. Before artificial intelligence (AI) becomes popular, such harmful contents have appeared on the social media. Back to the situation nowadays, some people have already had AI to help them post these contents. For example, an attack video made by AI tool called deepfake occurred in controversial territory between Pakistan and India, which will enhance the war tension [1]. As a result, it's significant to develop an AI-based method to mitigate this problem.

Several ways are defined to solve the problem about this field. There are machine learning, deep learning and generative AI. All methods need dataset from either public website or private collection, data preprocessing, model training and model evaluation. The series of behaviors are put together as an AI training framework [2]. After such complex procedure, the trained model will be discussed how well it performs in the true environment. In other words, the trained model will be tested in the real-time system and people will see whether it does work or not based on the statistical evaluation numbers, such as accuracy rate and F1-score [3]. In some conditions, it is successful to determine which content is detrimental. For example, “Drinking hot water, cow urine, alcohol have been recommended as a proven cure for COVID‐19”. Such confused sentence will be picked up and be marked as unknown or fake.

Even though AI can help us tackle this kind of problem, it still has issues to be improved like insufficient training data. That is, AI need more data to be trained repeatedly so that it can update its knowledge to recognize latest hate speech and fake news [4]. In addition, the AI model size and the network connecting condition are usually concerns that affect the time that it responses its answer to end users, so it may lower the user’s experience. These problems are ongoing challenges which modern AI tools have been facing. Regardless of limitation of AI, the combination method in AI and human help can be introduced to relieve the circumstance for recent challenges. For instance, the government from Kenya with United Nation help combines AI warning system and human inspection to prevent people from disinformation [5]. Such collaboration between AI and human could be a method enhancing the effectivity and the stability for existing system.

In conclusion, more improper contents are appearing by using AI on our social media. Thus, we have to develop a defensive method to mitigate the problem. For some cases, AI can detect these detrimental contents, but it still has drawback since it needs more data to update its knowledge database. Moreover, some problems will be considered like model size and network issue during real-time usage so as to function well. In terms of the system capability, we could combine AI and human determination to improve the accuracy rate of detection.

References
[1]	Libby Hogan, "Misinformation war rages online amid India-Pakistan tensions," ABC News, May. 24, 2025. [Online]. Available: https://www.abc.net.au/news/2025-05-24/misinformation-online-war-kashmir-conflict-india-pakistan/105318696
[2]	Gongane, V.U., Munot, M.V. & Anuse, A.D. A survey of explainable AI techniques for detection of fake news and hate speech on social media platforms. J Comput Soc Sc 7, 587–623 (2024). https://doi.org/10.1007/s42001-024-00248-9
[3]	Gongane, V.U., Munot, M.V. & Anuse, A.D. Detection and moderation of detrimental content on social media platforms: current status and future directions. Soc. Netw. Anal. Min. 12, 129 (2022). https://doi.org/10.1007/s13278-022-00951-3
[4]	P. Nedungadi, G. Veena, K. -Y. Tang, R. R. K. Menon and R. Raman, "AI Techniques and Applications for Online Social Networks and Media: Insights From BERTopic Modeling," in IEEE Access, vol. 13, pp. 37389-37407, 2025, doi: 10.1109/ACCESS.2025.3543795.
[5]	Nijwam Swargiary , " Tackling fake news in Kenya: A UN Resident Coordinator blog," UN News, Oct. 1, 2023. [Online]. Available: https://news.un.org/en/story/2023/10/1140862
